{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from pathlib import Path \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "import pickle\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "#matplotlib.use('Qt5Agg')\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get input data. Assumes data is stored in 'out_data' directory\n",
    "def getInput(file):    \n",
    "    all_epochs = mne.read_epochs(Path('out_data') / file )\n",
    "    idx_asd = all_epochs.events[:, 2] == all_epochs.event_id['asd']\n",
    "    idx_td = all_epochs.events[:, 2] == all_epochs.event_id['td']\n",
    "\n",
    "    # trails (epochs, channels, samples)\n",
    "    np_all_epochs = all_epochs.get_data()\n",
    "\n",
    "    print(f\"epochs: {np_all_epochs.shape[0]}, channels: {np_all_epochs.shape[1]}, samples: {np_all_epochs.shape[2]}\")\n",
    "    n_trials = np_all_epochs.shape[0]\n",
    "\n",
    "    # Labels\n",
    "    y = np.empty(len(all_epochs.events), dtype=int)  \n",
    "\n",
    "    # Encode: ASD = 0, TD = 1.\n",
    "    y[idx_asd] = 0\n",
    "    y[idx_td] = 1\n",
    "\n",
    "    return all_epochs, idx_asd, idx_td, np_all_epochs, y\n",
    "\n",
    "# Get input that includes extracted features\n",
    "def getProcessedInput(featureCount, fmax, np_all_epochs, all_epochs, featureExtractor):\n",
    "    X_2d = np.empty([np_all_epochs.shape[0], np_all_epochs.shape[1], featureCount], dtype=float)\n",
    "    psd_epochs_channels_freqs = all_epochs.compute_psd(fmax=fmax).get_data()  \n",
    "    for epoch_id, epoch in enumerate(psd_epochs_channels_freqs):\n",
    "        for channel_id, channel in enumerate(epoch):\n",
    "            X_2d[epoch_id, channel_id, :] = featureExtractor(channel)\n",
    "\n",
    "    n_trials = np_all_epochs.shape[0]\n",
    "    X_2d_reshaped = X_2d.reshape(n_trials, -1)\n",
    "    return X_2d_reshaped\n",
    "\n",
    "\n",
    "def visualizeResults(scores, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(scores,\n",
    "        showmeans=True, # Green triangle marks the mean.\n",
    "        whis=(0, 100),  # Whiskers span the entire range of the data.\n",
    "        labels=['ASD vs TD'])\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title(f'Cross-Validation Scores - {title}')\n",
    "    plt.show()\n",
    "\n",
    "def testModel(X, y, clf, cv, n_jobs, title, scoring=None):\n",
    "    scores_full = cross_val_score(clf, X, y, cv=cv, n_jobs=1, scoring=scoring)\n",
    "    print(f\"{title} Classification score: {np.mean(scores_full)} (std. {np.std(scores_full)})\")\n",
    "    visualizeResults(scores_full, title)\n",
    "\n",
    "\n",
    "def viewEpochChannelPSD(epoch, channel, matrix):\n",
    "    # View Epoch channel PSD\n",
    "    _, ax = plt.subplots()\n",
    "    _x = np.indices(matrix[epoch, channel, :].shape).squeeze()\n",
    "    ax.plot(_x , matrix[epoch, channel, :], color='k')\n",
    "    plt.show()\n",
    "\n",
    "def runTests(X_2d, y):\n",
    "    # Testing Parameters\n",
    "    #cv = ShuffleSplit(10, test_size=0.2, random_state=42)\n",
    "    n_splits = 5\n",
    "    scoring = 'roc_auc'\n",
    "    cv = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    # SVM\n",
    "    clf = SVC(C=1, kernel='linear')\n",
    "    testModel(X_2d, y, clf, cv, 1, \"SVM\", scoring)\n",
    "    saveModel(X_2d, y, clf, \"svm.model\")\n",
    "\n",
    " \n",
    "    # LDA\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    testModel(X_2d, y, clf, cv, 1, \"LDA\", scoring)\n",
    "    saveModel(X_2d, y, clf, \"lda.model\")\n",
    "\n",
    "    # Logistic Regression\n",
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        LogisticRegression(max_iter=500))\n",
    "    testModel(X_2d, y, clf, cv, 1, \"Logistic Regression\", scoring)\n",
    "    saveModel(X_2d, y, clf, \"lr.model\")\n",
    "\n",
    "def saveModel(X, y, clf, filename):\n",
    "    clf.fit(X, y)\n",
    "    pickle.dump(clf,open(f\"models/{filename}\", 'wb'))\n",
    "\n",
    "def extractFetures(signal):\n",
    "    delta = np.mean(signal[:4])\n",
    "    theta = np.mean(signal[4:8])\n",
    "    alpha = np.mean(signal[8:12])\n",
    "    beta = np.mean(signal[13:30])\n",
    "    gamma = np.mean(signal[30:40])\n",
    "    return [gamma]\n",
    "\n",
    "def main():\n",
    "    all_epochs, idx_asd, idx_td, np_all_epochs, y = getInput('train_all_epo.fif')\n",
    "    #X_2d = getProcessedInput(4, 30, np_all_epochs, all_epochs, extractFetures)\n",
    "    X_2d = getProcessedInput(1, 30, np_all_epochs, all_epochs, extractFetures)\n",
    "    runTests(X_2d, y)\n",
    "\n",
    "    #clf = make_pipeline(StandardScaler(), LogisticRegression(max_iter=500))\n",
    "    #clf = LinearDiscriminantAnalysis()\n",
    "    #clf = SVC(C=1, kernel='linear')\n",
    "    #saveModel(X_2d, y, clf, \"lr.model\")\n",
    "\n",
    "#main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate Model on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 216, channels: 32, samples: 513\n",
      "(108, 32) (108, 32)\n",
      "['Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'Oz', 'O2']\n",
      "[-1.71849410e-06 -2.26761995e-06 -2.28908584e-06] [-1.71849410e-06 -2.26761995e-06 -2.28908584e-06]\n"
     ]
    }
   ],
   "source": [
    "def extractFetures(signal):\n",
    "    delta = np.mean(signal[:4])\n",
    "    theta = np.mean(signal[4:8])\n",
    "    alpha = np.mean(signal[8:12])\n",
    "    beta = np.mean(signal[13:30])\n",
    "    gamma = np.mean(signal[30:40])\n",
    "    return [gamma]\n",
    "\n",
    "def testModel(X_2d, y, model_file, model_name):\n",
    "    #model_file = \"lr.model\"\n",
    "    loaded_model = pickle.load(open(f\"models/{model_file}\", 'rb'))\n",
    "    result = loaded_model.score(X_2d, y)\n",
    "    print(f\"{model_name} Classification score: {result}\")\n",
    "\n",
    "def main():\n",
    "    all_epochs, idx_asd, idx_td, np_all_epochs, y = getInput('test_all_epo.fif')\n",
    "    X_2d = getProcessedInput(1, 30, np_all_epochs, all_epochs, extractFetures)\n",
    "    channel_names = all_epochs.ch_names\n",
    "    #print(X_2d[idx_td].shape, X_2d[idx_asd].shape)\n",
    "    #all_epochs[0].plot()\n",
    "    #fp1 = all_epochs[0].pick_channels([\"Fp2\"])\n",
    "    #fp1.plot()\n",
    "    #fp1_data = fp1.get_data().squeeze()\n",
    "   \n",
    "    #print(\"fpz\", fp1_data.shape, fp1_data[:3])\n",
    "    #print(fp1_data[:3], np_all_epochs[0,2,:3])\n",
    "\n",
    "\n",
    "    #print(all_epochs.shape, np_all_epochs.shape)\n",
    "    #print(all_epochs)\n",
    "    #testModel(X_2d, y, \"svm.model\", \"SVM\")\n",
    "    #testModel(X_2d, y, \"lda.model\", \"LDA\")\n",
    "    #testModel(X_2d, y, \"lr.model\", \"LR\")\n",
    "\n",
    "\n",
    "    \n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbar_colors = [\\'tab:red\\', \\'tab:blue\\']\\nprint(\"ASD delta avg: \", np.mean(asd_powers[:, :, 0]))\\nprint(\"TD delta avg: \", np.mean(td_powers[:, :, 0]))\\nasd_mean_psd = np.mean(asd_powers[:, :, 0])\\ntd_mean_psd =  np.mean(td_powers[:, :, 0])\\ncounts = [asd_mean_psd, td_mean_psd]\\n        \\nfig, ax = plt.subplots()\\nax.bar(target_names, counts, color=bar_colors)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colors = [\"navy\", \"turquoise\"]\n",
    "#target_names = [\"asd\", \"td\"]\n",
    "\n",
    "#asd_powers = X_2d[idx_asd]\n",
    "#td_powers = X_2d[idx_td]\n",
    "\n",
    "#print(\"shape: \", asd_powers[:, :, 0].shape)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "fig, axs = plt.subplots(3, 4)\n",
    "\n",
    "channelid = 2\n",
    "for i in range(3):\n",
    "    for x in range(4):\n",
    "        axs[i, x].scatter(asd_powers[:, channelid, i], asd_powers[:, channelid, x], alpha=0.5, color=\"navy\", label=\"ASD\")\n",
    "        axs[i, x].scatter(td_powers[:, channelid, i], td_powers[:, channelid, x], alpha=0.5, color=\"turquoise\", label=\"TD\")\n",
    "        axs[i, x].legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
    "        axs[i, x].set_title(f'Axis [{i}, {x}]')\n",
    "'''\n",
    "\n",
    "'''\n",
    "bar_colors = ['tab:red', 'tab:blue']\n",
    "print(\"ASD delta avg: \", np.mean(asd_powers[:, :, 0]))\n",
    "print(\"TD delta avg: \", np.mean(td_powers[:, :, 0]))\n",
    "asd_mean_psd = np.mean(asd_powers[:, :, 0])\n",
    "td_mean_psd =  np.mean(td_powers[:, :, 0])\n",
    "counts = [asd_mean_psd, td_mean_psd]\n",
    "        \n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(target_names, counts, color=bar_colors)\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_analysis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d94503d86879015ebe7d306559351af4970b9a399c1ace7a1e2d9bc659cce61d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
