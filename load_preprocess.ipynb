{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path \n",
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import annotate_muscle_zscore\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.time_frequency import tfr_morlet\n",
    "import math\n",
    "from mne.preprocessing import (create_eog_epochs, create_ecg_epochs,\n",
    "                               corrmap)\n",
    "\n",
    "epochDuration = 1\n",
    "\n",
    "study_epochs = {\n",
    "    'td': [],\n",
    "    'asd': []\n",
    "}\n",
    "\n",
    "label_ids = {\n",
    "    \"asd\": 1,\n",
    "    \"td\": 2\n",
    "}\n",
    "\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# Set seed\n",
    "#random.seed(42) \n",
    "\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Raw EEG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/\")\n",
    "raw_eeg_path = data_path / \"raw_eeg\"\n",
    "\n",
    "def checkPath(dir):\n",
    "    # If the image folder doesn't exist, download it and prepare it... \n",
    "    if not data_path.is_dir():\n",
    "        logging.error(f\"{data_path} directory DOES NOT exists.\")\n",
    "\n",
    "def walkThroughDir(dir_path):\n",
    "    checkPath(dir_path)\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} file(s) in '{dirpath}'.\")\n",
    "\n",
    "# Assumes file is formatted as {ID}_{type}_{XXXHz}.{extension}. Example TD100_raw_512Hz.asc\n",
    "def csvToRaw(file, fMax=40):\n",
    "    print(f\"Processing {file.stem}\")\n",
    "    data = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "    try:\n",
    "        data =  data.drop(['VEOG - LkE', 'HEOG - LkE', 'Unnamed: 34'], axis=1)\n",
    "    except:\n",
    "        print(\"No EOG Channels found\")\n",
    "    # Get Channels\n",
    "    channels = list(data.columns)\n",
    "\n",
    "    # Format Channel names\n",
    "    f = lambda str: str.split(\"-\")[0].replace(\" \", \"\")\n",
    "    channels = [f(x) for x in channels]\n",
    "    channel_count = len(channels)\n",
    "\n",
    "    # Load Data\n",
    "    data = data.transpose()\n",
    "    ch_types = np.full((channel_count), \"eeg\")\n",
    "    sfreq = int(file.stem.split(\"_\")[2].replace(\"Hz\", \"\"))\n",
    "    info = mne.create_info(ch_names = channels, sfreq = sfreq, ch_types=ch_types)\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "\n",
    "    # Format data date for annotations later\n",
    "    raw.set_meas_date(0)\n",
    "    raw.set_montage(\"standard_1020\")\n",
    "\n",
    "    # Convert from uV to V for MNE\n",
    "    raw.apply_function(lambda x: x * 1e-6)\n",
    "\n",
    "    # Mark bad data\n",
    "    # Addressing this later now\n",
    "    markMuscleArtifacts(raw, 2)\n",
    "\n",
    "    filtered = raw.copy().filter(l_freq=1.0, h_freq=fMax)\n",
    "\n",
    "    return raw, filtered\n",
    "\n",
    "def markMuscleArtifacts(raw, threshold, plot=False):\n",
    "    #print(\"markMuscleArtifacts\")\n",
    "    threshold_muscle = threshold  # z-score\n",
    "    annot_muscle, scores_muscle = annotate_muscle_zscore(\n",
    "    raw, ch_type=\"eeg\", threshold=threshold_muscle, min_length_good=0.2,\n",
    "    filter_freq=[0, 60])\n",
    "    raw.set_annotations(annot_muscle)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        start = 512 * 10\n",
    "        end = 512 * 20\n",
    "        ax.plot(raw.times[:end], scores_muscle[:end])\n",
    "        ax.axhline(y=threshold_muscle, color='r')\n",
    "        ax.set(xlabel='time, (s)', ylabel='zscore', title='Muscle activity')\n",
    "        plt.show()\n",
    "    \n",
    "def createEvent(onset, label, sFreq):\n",
    "    return [onset * sFreq, 0, label]\n",
    "\n",
    "\n",
    "\n",
    "def getRandomFile(data_list):\n",
    "    random_raw_eeg_path = random.choice(data_list)\n",
    "    label = random_raw_eeg_path.parent.stem\n",
    "    return random_raw_eeg_path, label\n",
    "    \n",
    "\n",
    "def dropBadEpochs(epochs, plotLog=False):\n",
    "    reject_criteria = dict(eeg=150e-6) # 150 µV\n",
    "    flat_criteria = dict(eeg=1e-6) # 1 µV\n",
    "    epochs.drop_bad(reject=reject_criteria, flat=flat_criteria)\n",
    "    if plotLog: epochs.plot_drop_log()\n",
    "\n",
    "def runICA(epochs):\n",
    "    #print(\"Running ICA\")\n",
    "    n_components = 0.99  # Should normally be higher, like 0.999!!\n",
    "    method = 'picard'\n",
    "    fit_params = dict(fastica_it=5)\n",
    "    random_state = 42\n",
    "\n",
    "    ica = mne.preprocessing.ICA(n_components=n_components,\n",
    "        method=method,\n",
    "        fit_params=fit_params,\n",
    "        random_state=random_state)\n",
    "\n",
    "    ica.fit(epochs)\n",
    "    return ica\n",
    "\n",
    "def addEpochs(data, raw, start, file_length_seconds, label):\n",
    "    stop = start + epochDuration\n",
    "    events = mne.make_fixed_length_events(data,  label_ids[label], start=start, stop=file_length_seconds, duration=epochDuration)\n",
    "    epochs = mne.Epochs(data, events, tmin=0, tmax=epochDuration, event_id={label: label_ids[label]}, baseline=(0, 0), preload=True)\n",
    "    #epochs.plot(title=\"before\")\n",
    "    dropBadEpochs(epochs)\n",
    "   \n",
    "    \n",
    "    # Run ICA\n",
    "    ica = runICA(epochs)\n",
    "    eog_epochs = create_eog_epochs(raw, \"Fp1\")\n",
    "    eog_inds, eog_scores = ica.find_bads_eog(eog_epochs, \"Fp2\",  threshold=1.25)\n",
    "    ica.exclude = eog_inds\n",
    "    #print(eog_inds)\n",
    "\n",
    "    # Get Clean epochs\n",
    "    cleaned_epochs = ica.apply(epochs.copy())\n",
    "    #cleaned_epochs.plot(title=\"after\")\n",
    "    study_epochs[label].append(cleaned_epochs)\n",
    "    # update with cleaned epochs\n",
    "    return epochs\n",
    "\n",
    "def process(file):\n",
    "    raw, filtered = csvToRaw(file)\n",
    "    file_length = math.floor(len(filtered.times) / float(filtered.info['sfreq']))\n",
    "    #print(f\"{file_length}s file length\")\n",
    "    label = file.parent.stem\n",
    "    epochs = addEpochs(filtered, raw, 1.0, file_length, label)  # first ten seconds\n",
    "    return filtered, epochs\n",
    "\n",
    "def cleanData():\n",
    "    data_path_list = list(raw_eeg_path.glob(\"train/*/*.asc\"))\n",
    "    count = 0\n",
    "    #eeg_path, label = getRandomFile(data_path_list)\n",
    "    #filtered, epochs = process(eeg_path)\n",
    "\n",
    "    for file in data_path_list:\n",
    "        process(file)\n",
    "        count += 1\n",
    "\n",
    "    asd_concat_epochs = mne.concatenate_epochs(study_epochs['asd'])\n",
    "    td_concat_epochs = mne.concatenate_epochs(study_epochs['td'])\n",
    "    print(f\"{count} files processed.\")\n",
    "    print(f\"{len(study_epochs['asd'])} asd epoch objects\")\n",
    "    print(f\"{len(study_epochs['td'])} td td objects\")\n",
    "\n",
    "    # Drop Bad Epochs\n",
    "    #dropBadEpochs(asd_concat_epochs)\n",
    "    #asd_concat_epochs.plot()\n",
    "    td_concat_epochs.plot(title=\"TD Before Drop\")\n",
    "    td_concat_epochs.plot(title=\"TD After Drop\")\n",
    "\n",
    "\n",
    "    asd_concat_epochs.save(Path('out_data') / 'asd_concat_cleaned_1_40hz_epo.fif', overwrite=True)\n",
    "    td_concat_epochs.save(Path('out_data') / 'td_concat_cleaned_1_40hz_epo.fif', overwrite=True)\n",
    "\n",
    "    #asd_concat_epochs.plot()\n",
    "    #runICA(asd_concat_epochs)\n",
    "\n",
    "def icaClean():\n",
    "    asd_epochs = mne.read_epochs(Path('out_data') / 'asd_concat_cleaned_1_40hz_epo.fif')\n",
    "    td_epochs = mne.read_epochs(Path('out_data') / 'td_concat_cleaned_1_40hz_epo.fif')\n",
    "    #asd_epochs.plot(title=\"ASD\")\n",
    "    #td_epochs.plot(title=\"TD\")\n",
    "    ica = runICA(asd_epochs, \"ASD\")\n",
    "    ica.plot(title=\"ASD\")\n",
    "    #runICA(td_epochs, \"TD\")\n",
    "\n",
    "def processRandomFile():\n",
    "    data_path_list = list(raw_eeg_path.glob(\"train/*/*.asc\"))\n",
    "    eeg_path, label = getRandomFile(data_path_list)\n",
    "    filtered, epochs = process(eeg_path)\n",
    "    #epochs.compute_psd().plot()\n",
    "    \n",
    "processRandomFile()\n",
    "\n",
    "# cleanData()\n",
    "\n",
    "# icaClean()\n",
    "# main()\n",
    "#filtered.plot()\n",
    "#epochs.plot()\n",
    "\n",
    "# epochs.drop_bad(reject=reject_criteria, flat=flat_criteria)\n",
    "\n",
    "#epochs.plot_drop_log()\n",
    "\n",
    "# epochs['event'].plot_image()\n",
    "\n",
    "#epochs.plot_sensors(ch_type='all',title=\"sensors\")\n",
    "\n",
    "\n",
    "#asd_concat_epochs.save(Path('out_data') / 'asd_concat_epochs.fif', overwrite=True)\n",
    "#td_concat_epochs.save(Path('out_data') / 'td_concat_epochs.fif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42) \n",
    "\n",
    "asd_epochs = mne.read_epochs(Path('out_data') / 'asd_concat_cleaned_1_40hz_epo.fif')\n",
    "#asd_epochs['asd'].plot()\n",
    "\n",
    "td_epochs = mne.read_epochs(Path('out_data') / 'td_concat_cleaned_1_40hz_epo.fif')\n",
    "#td_epochs.plot()\n",
    "\n",
    "all_epochs = mne.concatenate_epochs([asd_epochs, td_epochs])\n",
    "#all_epochs.plot()\n",
    "\n",
    "#all_epochs.equalize_event_counts(all_epochs.event_id)\n",
    "#all_epochs\n",
    "\n",
    "#all_epochs.save(Path('out_data') / 'all_asd_td_concat_cleaned_1_40hz_epo.fif', overwrite=True)\n",
    "all_epochs = mne.read_epochs(Path('out_data') / 'all_asd_td_concat_cleaned_equal_1_40hz_epo.fif')\n",
    "all_epochs.plot()\n",
    "#print(all_epochs.events[:, 2])\n",
    "\n",
    "idx_asd = all_epochs.events[:, 2] == all_epochs.event_id['asd']\n",
    "idx_td = all_epochs.events[:, 2] == all_epochs.event_id['td']\n",
    "\n",
    "#y = np.empty(len(all_epochs.events), dtype=int)  \n",
    "#len(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Save Combined Raws and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data/\")\n",
    "raw_eeg_path = data_path / \"raw_eeg\"\n",
    "\n",
    "# Assumes file is formatted as {ID}_{type}_{XXXHz}.{extension}. Example TD100_raw_512Hz.asc\n",
    "def csvToRaw(file, fMax=40):\n",
    "    print(f\"Processing {file.stem}\")\n",
    "    data = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "    try:\n",
    "        data =  data.drop(['VEOG - LkE', 'HEOG - LkE', 'Unnamed: 34'], axis=1)\n",
    "    except:\n",
    "        print(\"No EOG Channels found\")\n",
    "\n",
    "    # Get Channels\n",
    "    channels = list(data.columns)\n",
    "\n",
    "    # Format Channel names\n",
    "    f = lambda str: str.split(\"-\")[0].replace(\" \", \"\")\n",
    "    channels = [f(x) for x in channels]\n",
    "    channel_count = len(channels)\n",
    "\n",
    "    # Load Data\n",
    "    data = data.transpose()\n",
    "    ch_types = np.full((channel_count), \"eeg\")\n",
    "    sfreq = int(file.stem.split(\"_\")[2].replace(\"Hz\", \"\"))\n",
    "    info = mne.create_info(ch_names = channels, sfreq = sfreq, ch_types=ch_types)\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "\n",
    "    # Format data date for annotations later\n",
    "    raw.set_meas_date(0)\n",
    "    raw.set_montage(\"standard_1020\")\n",
    "\n",
    "    # Convert from uV to V for MNE\n",
    "    raw.apply_function(lambda x: x * 1e-6)\n",
    "\n",
    "    # Mark bad data\n",
    "    # Addressing this later now\n",
    "    # markMuscleArtifacts(raw, 2)\n",
    "\n",
    "    filtered = raw.copy().filter(l_freq=1.0, h_freq=fMax)\n",
    "    return raw, filtered\n",
    "\n",
    "def combineRaws():\n",
    "    data_path_list = list(raw_eeg_path.glob(\"train/*/*.asc\"))\n",
    "    raws = {\n",
    "        \"td\":[],\n",
    "        \"asd\":[]\n",
    "    }\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    for file in data_path_list:\n",
    "        raw, filtered = csvToRaw(file)\n",
    "        file_length = math.floor(len(filtered.times) / float(filtered.info['sfreq']))\n",
    "        raws[file.parent.stem].append(raw)\n",
    "        print(f\"{file_length}s file length - {file.parent.stem}\")\n",
    "\n",
    "    \n",
    "    print(f\"{len(raws['asd'])} ASD raws. \")\n",
    "    print(f\"{len(raws['td'])} td raws. \")\n",
    "\n",
    "    combined_raw_asd = concatenate_raws(raws['asd'])\n",
    "    combined_raw_asd.save(Path('out_data') / 'raw_asd_combined_eeg.fif', overwrite=True)\n",
    "    #combined_raw_asd.plot()\n",
    "\n",
    "    combined_raw_td = concatenate_raws(raws['td'])\n",
    "    combined_raw_td.save(Path('out_data') / 'raw_td_combined_eeg.fif', overwrite=True)\n",
    "    #combined_raw_td.plot()\n",
    "\n",
    "#combineRaws()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#walkThroughDir(data_path)\n",
    "\n",
    "\n",
    "#print(asd_concat_epochs)\n",
    "\n",
    "#p.plot(title=\"Power\")\n",
    "\n",
    "'''\n",
    "for epochs in study_epochs['asd']:\n",
    "    #epochs = study_epochs[i]\n",
    "    p = epochs.compute_psd()\n",
    "    p.plot()\n",
    "'''\n",
    "\n",
    "#asd_concat_epochs.plot(title=\"ASD\")\n",
    "#td_concat_epochs.plot(title=\"TD\")\n",
    "\n",
    "#print(asd_concat_epochs)\n",
    "\n",
    "\n",
    "#asd_concat_epochs.plot_psd_topomap(ch_type='eeg')\n",
    "\n",
    "#print(td_concat_epochs)\n",
    "\n",
    "'''\n",
    "power_asd_concat_epochs = asd_concat_epochs.compute_psd()\n",
    "power_asd_concat_epochs.plot(title=\"power_asd_concat_epochs\")\n",
    "\n",
    "power_td_concat_epochs = td_concat_epochs.compute_psd()\n",
    "power_td_concat_epochs.plot(title=\"power_td_concat_epochs\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_analysis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d94503d86879015ebe7d306559351af4970b9a399c1ace7a1e2d9bc659cce61d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
