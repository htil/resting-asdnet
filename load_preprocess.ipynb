{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path \n",
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import annotate_muscle_zscore\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.time_frequency import tfr_morlet\n",
    "import math\n",
    "from mne.preprocessing import (create_eog_epochs, create_ecg_epochs,\n",
    "                               corrmap)\n",
    "matplotlib.use('Qt5Agg')\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# Set seed\n",
    "#random.seed(42) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Raw EEG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochDuration = 1\n",
    "\n",
    "study_epochs = {\n",
    "    'td': [],\n",
    "    'asd': []\n",
    "}\n",
    "\n",
    "label_ids = {\n",
    "    \"asd\": 1,\n",
    "    \"td\": 2\n",
    "}\n",
    "\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "raw_eeg_path = data_path / \"raw_eeg\"\n",
    "\n",
    "# Assumes file is formatted as {ID}_{type}_{XXXHz}.{extension}. Example TD100_raw_512Hz.asc\n",
    "def csvToRaw(file, fMax=40):\n",
    "    print(f\"Processing {file.stem}\")\n",
    "    data = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "    try:\n",
    "        data =  data.drop(['VEOG - LkE', 'HEOG - LkE', 'Unnamed: 34'], axis=1)\n",
    "    except:\n",
    "        print(\"No EOG Channels found\")\n",
    "    # Get Channels\n",
    "    channels = list(data.columns)\n",
    "\n",
    "    # Format Channel names\n",
    "    f = lambda str: str.split(\"-\")[0].replace(\" \", \"\")\n",
    "    channels = [f(x) for x in channels]\n",
    "    channel_count = len(channels)\n",
    "\n",
    "    # Load Data\n",
    "    data = data.transpose()\n",
    "    ch_types = np.full((channel_count), \"eeg\")\n",
    "    sfreq = int(file.stem.split(\"_\")[2].replace(\"Hz\", \"\"))\n",
    "    info = mne.create_info(ch_names = channels, sfreq = sfreq, ch_types=ch_types)\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "\n",
    "    # Format data date for annotations later\n",
    "    raw.set_meas_date(0)\n",
    "    raw.set_montage(\"standard_1020\")\n",
    "\n",
    "    # Convert from uV to V for MNE\n",
    "    raw.apply_function(lambda x: x * 1e-6)\n",
    "\n",
    "    # Mark bad data\n",
    "    # Addressing this later now\n",
    "    markMuscleArtifacts(raw, 2)\n",
    "\n",
    "    filtered = raw.copy().filter(l_freq=1.0, h_freq=fMax)\n",
    "\n",
    "    return raw, filtered\n",
    "\n",
    "# Find bad spans of data using mne.preprocessing.annotate_muscle_zscore\n",
    "def markMuscleArtifacts(raw, threshold, plot=False):\n",
    "    #print(\"markMuscleArtifacts\")\n",
    "    threshold_muscle = threshold  # z-score\n",
    "    annot_muscle, scores_muscle = annotate_muscle_zscore(\n",
    "    raw, ch_type=\"eeg\", threshold=threshold_muscle, min_length_good=0.2,\n",
    "    filter_freq=[0, 60])\n",
    "    raw.set_annotations(annot_muscle)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        start = 512 * 10\n",
    "        end = 512 * 20\n",
    "        ax.plot(raw.times[:end], scores_muscle[:end])\n",
    "        ax.axhline(y=threshold_muscle, color='r')\n",
    "        ax.set(xlabel='time, (s)', ylabel='zscore', title='Muscle activity')\n",
    "        plt.show()\n",
    "\n",
    "# Reject epochs based on maximum acceptable peak-to-peak amplitude \n",
    "# https://mne.tools/stable/auto_tutorials/preprocessing/20_rejecting_bad_data.html#sphx-glr-auto-tutorials-preprocessing-20-rejecting-bad-data-py\n",
    "def dropBadEpochs(epochs, plotLog=False):\n",
    "    reject_criteria = dict(eeg=150e-6) # 150 µV\n",
    "    flat_criteria = dict(eeg=1e-6) # 1 µV\n",
    "    epochs.drop_bad(reject=reject_criteria, flat=flat_criteria)\n",
    "    if plotLog: epochs.plot_drop_log()\n",
    "\n",
    "# Get ICs \n",
    "def runICA(epochs):\n",
    "    #print(\"Running ICA\")\n",
    "    n_components = 0.99  # Should normally be higher, like 0.999!!\n",
    "    method = 'picard'\n",
    "    fit_params = dict(fastica_it=5)\n",
    "    random_state = 42\n",
    "\n",
    "    ica = mne.preprocessing.ICA(n_components=n_components,\n",
    "        method=method,\n",
    "        fit_params=fit_params,\n",
    "        random_state=random_state)\n",
    "\n",
    "    ica.fit(epochs)\n",
    "    return ica\n",
    "\n",
    "# Create epoch data, get ICs, and add to study_epochs object\n",
    "def addEpochs(data, raw, start, file_length_seconds, label, file=\"\"):\n",
    "    stop = start + epochDuration\n",
    "    events = mne.make_fixed_length_events(data,  label_ids[label], start=start, stop=file_length_seconds, duration=epochDuration)\n",
    "    epochs = mne.Epochs(data, events, tmin=0, tmax=epochDuration, event_id={label: label_ids[label]}, baseline=(0, 0), preload=True)\n",
    "    #epochs.plot(title=\"before\")\n",
    "    dropBadEpochs(epochs)\n",
    "   \n",
    "    # Run ICA\n",
    "    ica = runICA(epochs)\n",
    "    eog_epochs = create_eog_epochs(raw, \"Fp1\")\n",
    "    eog_inds, eog_scores = ica.find_bads_eog(eog_epochs, \"Fp2\",  threshold=1.25)\n",
    "    ica.exclude = eog_inds\n",
    "    #print(eog_inds)\n",
    "\n",
    "    # Get Clean epochs\n",
    "    cleaned_epochs = ica.apply(epochs.copy())\n",
    "    #fig = cleaned_epochs.compute_psd().plot()\n",
    "    #fig.suptitle(file, fontsize=16)\n",
    "\n",
    "    #cleaned_epochs.plot(title=\"after\")\n",
    "    study_epochs[label].append(cleaned_epochs)\n",
    "    # update with cleaned epochs\n",
    "    return epochs\n",
    "\n",
    "# Process raw file. \n",
    "def process(file):\n",
    "    raw, filtered = csvToRaw(file)\n",
    "    #fig = filtered.compute_psd().plot()\n",
    "    file_length = math.floor(len(filtered.times) / float(filtered.info['sfreq']))\n",
    "    #print(f\"{file_length}s file length\")\n",
    "    label = file.parent.stem\n",
    "    epochs = addEpochs(filtered, raw, 1.0, file_length, label, file)  # first ten seconds\n",
    "    return filtered, epochs\n",
    "\n",
    "\n",
    "# Clean all data in the file paths added to data_path_list\n",
    "def cleanData(dir):\n",
    "    data_path_list = list(raw_eeg_path.glob(f\"{dir}/*/*.asc\"))\n",
    "    count = 0\n",
    "\n",
    "    for file in data_path_list:\n",
    "        process(file)\n",
    "        count += 1\n",
    "\n",
    "    asd_concat_epochs = mne.concatenate_epochs(study_epochs['asd'])\n",
    "    td_concat_epochs = mne.concatenate_epochs(study_epochs['td'])\n",
    "    print(f\"{count} files processed.\")\n",
    "    print(f\"{len(study_epochs['asd'])} asd epoch objects\")\n",
    "    print(f\"{len(study_epochs['td'])} td td objects\")\n",
    "    #asd_concat_epochs.plot()\n",
    "    #td_concat_epochs.plot()\n",
    "    asd_concat_epochs.save(Path('out_data') / f'{dir}_asd_concat_cleaned_1_40hz_epo.fif', overwrite=True)\n",
    "    td_concat_epochs.save(Path('out_data') / f'{dir}_td_concat_cleaned_1_40hz_epo.fif', overwrite=True)\n",
    "    train_all_epochs = mne.concatenate_epochs([asd_concat_epochs, td_concat_epochs])\n",
    "    train_all_epochs.equalize_event_counts(train_all_epochs.event_id)\n",
    "    train_all_epochs.save(Path('out_data') / f'{dir}_all_epo.fif')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "cleanData(\"train\")\n",
    "# processRandomFile()\n",
    "# icaClean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 61)\n"
     ]
    }
   ],
   "source": [
    "    asd_epochs = mne.read_epochs(Path('out_data') / 'train_asd_concat_cleaned_1_40hz_epo.fif')\n",
    "    td_epochs = mne.read_epochs(Path('out_data') / 'train_td_concat_cleaned_1_40hz_epo.fif')\n",
    "\n",
    "    #fig = asd_epochs.compute_psd(fmax=60).plot(average=True)\n",
    "    #fig.suptitle(\"asd\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove (ASD)\n",
    "- 110\n",
    "- 105\n",
    "- 102\n",
    "- 106\n",
    "\n",
    "Remove\n",
    "- TD102\n",
    "- TD103\n",
    "- TD107 - wrong channel format\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Additional Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icaClean():\n",
    "    asd_epochs = mne.read_epochs(Path('out_data') / 'asd_concat_cleaned_1_40hz_epo.fif')\n",
    "    td_epochs = mne.read_epochs(Path('out_data') / 'td_concat_cleaned_1_40hz_epo.fif')\n",
    "    #asd_epochs.plot(title=\"ASD\")\n",
    "    #td_epochs.plot(title=\"TD\")\n",
    "    ica = runICA(asd_epochs, \"ASD\")\n",
    "    ica.plot(title=\"ASD\")\n",
    "\n",
    "def checkPath(dir):\n",
    "    # If the image folder doesn't exist, download it and prepare it... \n",
    "    if not data_path.is_dir():\n",
    "        logging.error(f\"{data_path} directory DOES NOT exists.\")\n",
    "\n",
    "def walkThroughDir(dir_path):\n",
    "    checkPath(dir_path)\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} file(s) in '{dirpath}'.\")\n",
    "\n",
    "def createEvent(onset, label, sFreq):\n",
    "    return [onset * sFreq, 0, label]\n",
    "\n",
    "\n",
    "def getRandomFile(data_list):\n",
    "    random_raw_eeg_path = random.choice(data_list)\n",
    "    label = random_raw_eeg_path.parent.stem\n",
    "    return random_raw_eeg_path, label\n",
    "\n",
    "def processRandomFile():\n",
    "    data_path_list = list(raw_eeg_path.glob(\"train/*/*.asc\"))\n",
    "    eeg_path, label = getRandomFile(data_path_list)\n",
    "    filtered, epochs = process(eeg_path)\n",
    "    #epochs.compute_psd().plot()\n",
    "\n",
    "def visualizePower(minFreq, maxFreq, epochs, plotChannels=True, plotTopo=True, event=\"\"):\n",
    "    freqs = np.logspace(*np.log10([minFreq, maxFreq]), num=128)\n",
    "    # freqs = np.arange(1, 32, 0.25)\n",
    "    n_cycles = freqs / 2.  # different number of cycle per frequency\n",
    "    power, itc = tfr_morlet(epochs, freqs=freqs, n_cycles=n_cycles, use_fft=True, return_itc=True, decim=3, n_jobs=None)\n",
    "\n",
    "    if plotChannels:\n",
    "        for i in range(len(power.ch_names)):\n",
    "            power.plot([i], baseline=(-0.5, 0), mode='logratio', title=(event + \" \" + power.ch_names[i]))\n",
    "\n",
    "\n",
    "    topomap_kw = dict(ch_type='eeg', tmin=0, tmax=1.0, mode='logratio', show=False)\n",
    "    plot_dict = dict(Delta=dict(fmin=0, fmax=4), Alpha=dict(fmin=7, fmax=12), Beta=dict(fmin=13, fmax=25))\n",
    "    \n",
    "    if plotTopo:\n",
    "        power.plot_topo(baseline=(-0.5, 0), mode='logratio', title='Average power')\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(10, 7))\n",
    "        for ax, (title, fmin_fmax) in zip(axes, plot_dict.items()):\n",
    "            power.plot_topomap(**fmin_fmax, axes=ax, **topomap_kw, show_names=True)\n",
    "            ax.set_title(event + \" \" + title)\n",
    "    \n",
    "        fig.tight_layout()\n",
    "        fig.show()\n",
    "    return power\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. (Example) Load and Combine Existing Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_asd_epochs = mne.read_epochs(Path('out_data') / 'test_asd_concat_cleaned_1_40hz_epo.fif')\n",
    "    test_td_epochs = mne.read_epochs(Path('out_data') / 'test_td_concat_cleaned_1_40hz_epo.fif')\n",
    "    test_all_epochs = mne.concatenate_epochs([test_asd_epochs, test_td_epochs])\n",
    "\n",
    "    # Set if you want to equalize the event counts\n",
    "    test_all_epochs.equalize_event_counts(test_all_epochs.event_id)\n",
    "    \n",
    "    test_all_epochs.save(Path('out_data') / 'test_all_cleaned_equal_1_40hz_epo.fif')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. (Example) Create and Save Combined Raws and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineRaws():\n",
    "    data_path_list = list(raw_eeg_path.glob(\"train/*/*.asc\"))\n",
    "    raws = {\n",
    "        \"td\":[],\n",
    "        \"asd\":[]\n",
    "    }\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    for file in data_path_list:\n",
    "        raw, filtered = csvToRaw(file)\n",
    "        file_length = math.floor(len(filtered.times) / float(filtered.info['sfreq']))\n",
    "        raws[file.parent.stem].append(raw)\n",
    "        print(f\"{file_length}s file length - {file.parent.stem}\")\n",
    "\n",
    "    \n",
    "    print(f\"{len(raws['asd'])} ASD raws. \")\n",
    "    print(f\"{len(raws['td'])} td raws. \")\n",
    "\n",
    "    combined_raw_asd = concatenate_raws(raws['asd'])\n",
    "    combined_raw_asd.save(Path('out_data') / 'raw_asd_combined_eeg.fif', overwrite=True)\n",
    "    #combined_raw_asd.plot()\n",
    "\n",
    "    combined_raw_td = concatenate_raws(raws['td'])\n",
    "    combined_raw_td.save(Path('out_data') / 'raw_td_combined_eeg.fif', overwrite=True)\n",
    "    #combined_raw_td.plot()\n",
    "\n",
    "#combineRaws()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
