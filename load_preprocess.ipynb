{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import torch\n",
    "import os\n",
    "from pathlib import Path \n",
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import annotate_muscle_zscore\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.time_frequency import tfr_morlet\n",
    "import math\n",
    "from mne.preprocessing import (create_eog_epochs, create_ecg_epochs,\n",
    "                               corrmap)\n",
    "matplotlib.use('Qt5Agg')\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# Set seed\n",
    "#random.seed(42) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Raw EEG Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TD109_raw_512Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12052\\AppData\\Local\\Temp\\ipykernel_13316\\2134379712.py:95: RuntimeWarning: The epochs you passed to ICA.fit() were baseline-corrected. However, we suggest to fit ICA only on data that has been high-pass filtered, but NOT baseline-corrected.\n",
      "  ica.fit(epochs)\n",
      "C:\\Users\\12052\\AppData\\Local\\Temp\\ipykernel_13316\\2134379712.py:114: RuntimeWarning: The data you passed to ICA.apply() was baseline-corrected. Please note that ICA can introduce DC shifts, therefore you may wish to consider baseline-correcting the cleaned data again.\n",
      "  cleaned_epochs = ica.apply(epochs.copy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TD108_raw_512Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12052\\AppData\\Local\\Temp\\ipykernel_13316\\2134379712.py:95: RuntimeWarning: The epochs you passed to ICA.fit() were baseline-corrected. However, we suggest to fit ICA only on data that has been high-pass filtered, but NOT baseline-corrected.\n",
      "  ica.fit(epochs)\n",
      "C:\\Users\\12052\\AppData\\Local\\Temp\\ipykernel_13316\\2134379712.py:114: RuntimeWarning: The data you passed to ICA.apply() was baseline-corrected. Please note that ICA can introduce DC shifts, therefore you may wish to consider baseline-correcting the cleaned data again.\n",
      "  cleaned_epochs = ica.apply(epochs.copy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing A109_raw_512Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12052\\AppData\\Local\\Temp\\ipykernel_13316\\2134379712.py:95: RuntimeWarning: The epochs you passed to ICA.fit() were baseline-corrected. However, we suggest to fit ICA only on data that has been high-pass filtered, but NOT baseline-corrected.\n",
      "  ica.fit(epochs)\n",
      "C:\\Users\\12052\\AppData\\Local\\Temp\\ipykernel_13316\\2134379712.py:114: RuntimeWarning: The data you passed to ICA.apply() was baseline-corrected. Please note that ICA can introduce DC shifts, therefore you may wish to consider baseline-correcting the cleaned data again.\n",
      "  cleaned_epochs = ica.apply(epochs.copy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing A105_raw_512Hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12052\\AppData\\Local\\Temp\\ipykernel_13316\\2134379712.py:95: RuntimeWarning: The epochs you passed to ICA.fit() were baseline-corrected. However, we suggest to fit ICA only on data that has been high-pass filtered, but NOT baseline-corrected.\n",
      "  ica.fit(epochs)\n",
      "C:\\Users\\12052\\AppData\\Local\\Temp\\ipykernel_13316\\2134379712.py:114: RuntimeWarning: The data you passed to ICA.apply() was baseline-corrected. Please note that ICA can introduce DC shifts, therefore you may wish to consider baseline-correcting the cleaned data again.\n",
      "  cleaned_epochs = ica.apply(epochs.copy())\n",
      "C:\\Users\\12052\\AppData\\Local\\Temp\\ipykernel_13316\\2134379712.py:139: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  asd_concat_epochs = mne.concatenate_epochs(study_epochs['asd'])\n",
      "C:\\Users\\12052\\AppData\\Local\\Temp\\ipykernel_13316\\2134379712.py:140: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  td_concat_epochs = mne.concatenate_epochs(study_epochs['td'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 files processed.\n",
      "2 asd epoch objects\n",
      "2 td td objects\n"
     ]
    }
   ],
   "source": [
    "epochDuration = 1\n",
    "\n",
    "study_epochs = {\n",
    "    'td': [],\n",
    "    'asd': []\n",
    "}\n",
    "\n",
    "label_ids = {\n",
    "    \"asd\": 1,\n",
    "    \"td\": 2\n",
    "}\n",
    "\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "raw_eeg_path = data_path / \"raw_eeg\"\n",
    "\n",
    "# Assumes file is formatted as {ID}_{type}_{XXXHz}.{extension}. Example TD100_raw_512Hz.asc\n",
    "def csvToRaw(file, fMax=40):\n",
    "    print(f\"Processing {file.stem}\")\n",
    "    data = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "    try:\n",
    "        data =  data.drop(['VEOG - LkE', 'HEOG - LkE', 'Unnamed: 34'], axis=1)\n",
    "    except:\n",
    "        print(\"No EOG Channels found\")\n",
    "    # Get Channels\n",
    "    channels = list(data.columns)\n",
    "\n",
    "    # Format Channel names\n",
    "    f = lambda str: str.split(\"-\")[0].replace(\" \", \"\")\n",
    "    channels = [f(x) for x in channels]\n",
    "    channel_count = len(channels)\n",
    "\n",
    "    # Load Data\n",
    "    data = data.transpose()\n",
    "    ch_types = np.full((channel_count), \"eeg\")\n",
    "    sfreq = int(file.stem.split(\"_\")[2].replace(\"Hz\", \"\"))\n",
    "    info = mne.create_info(ch_names = channels, sfreq = sfreq, ch_types=ch_types)\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "\n",
    "    # Format data date for annotations later\n",
    "    raw.set_meas_date(0)\n",
    "    raw.set_montage(\"standard_1020\")\n",
    "\n",
    "    # Convert from uV to V for MNE\n",
    "    raw.apply_function(lambda x: x * 1e-6)\n",
    "\n",
    "    # Mark bad data\n",
    "    # Addressing this later now\n",
    "    markMuscleArtifacts(raw, 2)\n",
    "\n",
    "    filtered = raw.copy().filter(l_freq=1.0, h_freq=fMax)\n",
    "\n",
    "    return raw, filtered\n",
    "\n",
    "# Find bad spans of data using mne.preprocessing.annotate_muscle_zscore\n",
    "def markMuscleArtifacts(raw, threshold, plot=False):\n",
    "    #print(\"markMuscleArtifacts\")\n",
    "    threshold_muscle = threshold  # z-score\n",
    "    annot_muscle, scores_muscle = annotate_muscle_zscore(\n",
    "    raw, ch_type=\"eeg\", threshold=threshold_muscle, min_length_good=0.2,\n",
    "    filter_freq=[0, 60])\n",
    "    raw.set_annotations(annot_muscle)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        start = 512 * 10\n",
    "        end = 512 * 20\n",
    "        ax.plot(raw.times[:end], scores_muscle[:end])\n",
    "        ax.axhline(y=threshold_muscle, color='r')\n",
    "        ax.set(xlabel='time, (s)', ylabel='zscore', title='Muscle activity')\n",
    "        plt.show()\n",
    "\n",
    "# Reject epochs based on maximum acceptable peak-to-peak amplitude \n",
    "# https://mne.tools/stable/auto_tutorials/preprocessing/20_rejecting_bad_data.html#sphx-glr-auto-tutorials-preprocessing-20-rejecting-bad-data-py\n",
    "def dropBadEpochs(epochs, plotLog=False):\n",
    "    reject_criteria = dict(eeg=150e-6) # 150 µV\n",
    "    flat_criteria = dict(eeg=1e-6) # 1 µV\n",
    "    epochs.drop_bad(reject=reject_criteria, flat=flat_criteria)\n",
    "    if plotLog: epochs.plot_drop_log()\n",
    "\n",
    "# Get ICs \n",
    "def runICA(epochs):\n",
    "    #print(\"Running ICA\")\n",
    "    n_components = 0.99  # Should normally be higher, like 0.999!!\n",
    "    method = 'picard'\n",
    "    fit_params = dict(fastica_it=5)\n",
    "    random_state = 42\n",
    "\n",
    "    ica = mne.preprocessing.ICA(n_components=n_components,\n",
    "        method=method,\n",
    "        fit_params=fit_params,\n",
    "        random_state=random_state)\n",
    "\n",
    "    ica.fit(epochs)\n",
    "    return ica\n",
    "\n",
    "# Create epoch data, get ICs, and add to study_epochs object\n",
    "def addEpochs(data, raw, start, file_length_seconds, label):\n",
    "    stop = start + epochDuration\n",
    "    events = mne.make_fixed_length_events(data,  label_ids[label], start=start, stop=file_length_seconds, duration=epochDuration)\n",
    "    epochs = mne.Epochs(data, events, tmin=0, tmax=epochDuration, event_id={label: label_ids[label]}, baseline=(0, 0), preload=True)\n",
    "    #epochs.plot(title=\"before\")\n",
    "    dropBadEpochs(epochs)\n",
    "   \n",
    "    # Run ICA\n",
    "    ica = runICA(epochs)\n",
    "    eog_epochs = create_eog_epochs(raw, \"Fp1\")\n",
    "    eog_inds, eog_scores = ica.find_bads_eog(eog_epochs, \"Fp2\",  threshold=1.25)\n",
    "    ica.exclude = eog_inds\n",
    "    #print(eog_inds)\n",
    "\n",
    "    # Get Clean epochs\n",
    "    cleaned_epochs = ica.apply(epochs.copy())\n",
    "    #cleaned_epochs.plot(title=\"after\")\n",
    "    study_epochs[label].append(cleaned_epochs)\n",
    "    # update with cleaned epochs\n",
    "    return epochs\n",
    "\n",
    "# Process raw file. \n",
    "def process(file):\n",
    "    raw, filtered = csvToRaw(file)\n",
    "    file_length = math.floor(len(filtered.times) / float(filtered.info['sfreq']))\n",
    "    #print(f\"{file_length}s file length\")\n",
    "    label = file.parent.stem\n",
    "    epochs = addEpochs(filtered, raw, 1.0, file_length, label)  # first ten seconds\n",
    "    return filtered, epochs\n",
    "\n",
    "\n",
    "# Clean all data in the file paths added to data_path_list\n",
    "def cleanData(dir):\n",
    "    data_path_list = list(raw_eeg_path.glob(f\"{dir}/*/*.asc\"))\n",
    "    count = 0\n",
    "\n",
    "    for file in data_path_list:\n",
    "        process(file)\n",
    "        count += 1\n",
    "\n",
    "    asd_concat_epochs = mne.concatenate_epochs(study_epochs['asd'])\n",
    "    td_concat_epochs = mne.concatenate_epochs(study_epochs['td'])\n",
    "    print(f\"{count} files processed.\")\n",
    "    print(f\"{len(study_epochs['asd'])} asd epoch objects\")\n",
    "    print(f\"{len(study_epochs['td'])} td td objects\")\n",
    "    #asd_concat_epochs.plot()\n",
    "    #td_concat_epochs.plot()\n",
    "    asd_concat_epochs.save(Path('out_data') / f'{dir}_asd_concat_cleaned_1_40hz_epo.fif', overwrite=True)\n",
    "    td_concat_epochs.save(Path('out_data') / f'{dir}_td_concat_cleaned_1_40hz_epo.fif', overwrite=True)\n",
    "    train_all_epochs = mne.concatenate_epochs([asd_concat_epochs, td_concat_epochs])\n",
    "    train_all_epochs.equalize_event_counts(train_all_epochs.event_id)\n",
    "    train_all_epochs.save(Path('out_data') / f'{dir}_all_epo.fif')\n",
    "\n",
    "    \n",
    "cleanData(\"test\")\n",
    "# processRandomFile()\n",
    "# icaClean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Additional Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icaClean():\n",
    "    asd_epochs = mne.read_epochs(Path('out_data') / 'asd_concat_cleaned_1_40hz_epo.fif')\n",
    "    td_epochs = mne.read_epochs(Path('out_data') / 'td_concat_cleaned_1_40hz_epo.fif')\n",
    "    #asd_epochs.plot(title=\"ASD\")\n",
    "    #td_epochs.plot(title=\"TD\")\n",
    "    ica = runICA(asd_epochs, \"ASD\")\n",
    "    ica.plot(title=\"ASD\")\n",
    "\n",
    "def checkPath(dir):\n",
    "    # If the image folder doesn't exist, download it and prepare it... \n",
    "    if not data_path.is_dir():\n",
    "        logging.error(f\"{data_path} directory DOES NOT exists.\")\n",
    "\n",
    "def walkThroughDir(dir_path):\n",
    "    checkPath(dir_path)\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} file(s) in '{dirpath}'.\")\n",
    "\n",
    "def createEvent(onset, label, sFreq):\n",
    "    return [onset * sFreq, 0, label]\n",
    "\n",
    "\n",
    "def getRandomFile(data_list):\n",
    "    random_raw_eeg_path = random.choice(data_list)\n",
    "    label = random_raw_eeg_path.parent.stem\n",
    "    return random_raw_eeg_path, label\n",
    "\n",
    "def processRandomFile():\n",
    "    data_path_list = list(raw_eeg_path.glob(\"train/*/*.asc\"))\n",
    "    eeg_path, label = getRandomFile(data_path_list)\n",
    "    filtered, epochs = process(eeg_path)\n",
    "    #epochs.compute_psd().plot()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. (Example) Load and Combine Existing Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File does not exist: \\\\wsl$\\Ubuntu-20.04\\home\\csc\\Projects\\eeg_analysis\\eeg_analysis2\\out_data\\test_asd_concat_cleaned_1_40hz_epo.fif",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_asd_epochs \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39;49mread_epochs(Path(\u001b[39m'\u001b[39;49m\u001b[39mout_data\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m/\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mtest_asd_concat_cleaned_1_40hz_epo.fif\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m test_td_epochs \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39mread_epochs(Path(\u001b[39m'\u001b[39m\u001b[39mout_data\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest_td_concat_cleaned_1_40hz_epo.fif\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m test_all_epochs \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39mconcatenate_epochs([test_asd_epochs, test_td_epochs])\n",
      "File \u001b[1;32m<decorator-gen-284>:12\u001b[0m, in \u001b[0;36mread_epochs\u001b[1;34m(fname, proj, preload, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\12052\\anaconda3\\envs\\eeg_analysis2\\lib\\site-packages\\mne\\epochs.py:3176\u001b[0m, in \u001b[0;36mread_epochs\u001b[1;34m(fname, proj, preload, verbose)\u001b[0m\n\u001b[0;32m   3158\u001b[0m \u001b[39m@verbose\u001b[39m\n\u001b[0;32m   3159\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_epochs\u001b[39m(fname, proj\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, preload\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   3160\u001b[0m     \u001b[39m\"\"\"Read epochs from a fif file.\u001b[39;00m\n\u001b[0;32m   3161\u001b[0m \n\u001b[0;32m   3162\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3174\u001b[0m \u001b[39m        The epochs.\u001b[39;00m\n\u001b[0;32m   3175\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3176\u001b[0m     \u001b[39mreturn\u001b[39;00m EpochsFIF(fname, proj, preload, verbose)\n",
      "File \u001b[1;32m<decorator-gen-285>:12\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, fname, proj, preload, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\12052\\anaconda3\\envs\\eeg_analysis2\\lib\\site-packages\\mne\\epochs.py:3224\u001b[0m, in \u001b[0;36mEpochsFIF.__init__\u001b[1;34m(self, fname, proj, preload, verbose)\u001b[0m\n\u001b[0;32m   3219\u001b[0m \u001b[39mif\u001b[39;00m _path_like(fname):\n\u001b[0;32m   3220\u001b[0m     check_fname(\n\u001b[0;32m   3221\u001b[0m         fname\u001b[39m=\u001b[39mfname, filetype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   3222\u001b[0m         endings\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-epo.fif\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-epo.fif.gz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_epo.fif\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_epo.fif.gz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   3223\u001b[0m     )\n\u001b[1;32m-> 3224\u001b[0m     fname \u001b[39m=\u001b[39m _check_fname(fname\u001b[39m=\u001b[39;49mfname, must_exist\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   3225\u001b[0m                          overwrite\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mread\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m   3226\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m preload:\n\u001b[0;32m   3227\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mpreload must be used with file-like objects\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m<decorator-gen-0>:12\u001b[0m, in \u001b[0;36m_check_fname\u001b[1;34m(fname, overwrite, must_exist, name, need_dir, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\12052\\anaconda3\\envs\\eeg_analysis2\\lib\\site-packages\\mne\\utils\\check.py:245\u001b[0m, in \u001b[0;36m_check_fname\u001b[1;34m(fname, overwrite, must_exist, name, need_dir, verbose)\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mPermissionError\u001b[39;00m(\n\u001b[0;32m    243\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not have read permissions: \u001b[39m\u001b[39m{\u001b[39;00mfname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    244\u001b[0m \u001b[39melif\u001b[39;00m must_exist:\n\u001b[1;32m--> 245\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not exist: \u001b[39m\u001b[39m{\u001b[39;00mfname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    247\u001b[0m \u001b[39mreturn\u001b[39;00m fname\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File does not exist: \\\\wsl$\\Ubuntu-20.04\\home\\csc\\Projects\\eeg_analysis\\eeg_analysis2\\out_data\\test_asd_concat_cleaned_1_40hz_epo.fif"
     ]
    }
   ],
   "source": [
    "    test_asd_epochs = mne.read_epochs(Path('out_data') / 'test_asd_concat_cleaned_1_40hz_epo.fif')\n",
    "    test_td_epochs = mne.read_epochs(Path('out_data') / 'test_td_concat_cleaned_1_40hz_epo.fif')\n",
    "    test_all_epochs = mne.concatenate_epochs([test_asd_epochs, test_td_epochs])\n",
    "\n",
    "    # Set if you want to equalize the event counts\n",
    "    test_all_epochs.equalize_event_counts(test_all_epochs.event_id)\n",
    "    \n",
    "    test_all_epochs.save(Path('out_data') / 'test_all_cleaned_equal_1_40hz_epo.fif')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. (Example) Create and Save Combined Raws and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineRaws():\n",
    "    data_path_list = list(raw_eeg_path.glob(\"train/*/*.asc\"))\n",
    "    raws = {\n",
    "        \"td\":[],\n",
    "        \"asd\":[]\n",
    "    }\n",
    "    \n",
    "    count = 0\n",
    "\n",
    "    for file in data_path_list:\n",
    "        raw, filtered = csvToRaw(file)\n",
    "        file_length = math.floor(len(filtered.times) / float(filtered.info['sfreq']))\n",
    "        raws[file.parent.stem].append(raw)\n",
    "        print(f\"{file_length}s file length - {file.parent.stem}\")\n",
    "\n",
    "    \n",
    "    print(f\"{len(raws['asd'])} ASD raws. \")\n",
    "    print(f\"{len(raws['td'])} td raws. \")\n",
    "\n",
    "    combined_raw_asd = concatenate_raws(raws['asd'])\n",
    "    combined_raw_asd.save(Path('out_data') / 'raw_asd_combined_eeg.fif', overwrite=True)\n",
    "    #combined_raw_asd.plot()\n",
    "\n",
    "    combined_raw_td = concatenate_raws(raws['td'])\n",
    "    combined_raw_td.save(Path('out_data') / 'raw_td_combined_eeg.fif', overwrite=True)\n",
    "    #combined_raw_td.plot()\n",
    "\n",
    "#combineRaws()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg_analysis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d94503d86879015ebe7d306559351af4970b9a399c1ace7a1e2d9bc659cce61d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
