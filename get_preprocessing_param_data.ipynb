{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg\n",
      "TD109_raw_512Hz\n",
      "Processing TD109_raw_512Hz\n",
      "td\n",
      "TD110_raw_512Hz\n",
      "Processing TD110_raw_512Hz\n",
      "td\n",
      "TD107_raw_512Hz\n",
      "Processing TD107_raw_512Hz\n",
      "td\n",
      "TD108_raw_512Hz\n",
      "Processing TD108_raw_512Hz\n",
      "td\n",
      "TD106_raw_512Hz\n",
      "Processing TD106_raw_512Hz\n",
      "td\n",
      "TD113_raw_512Hz\n",
      "Processing TD113_raw_512Hz\n",
      "td\n",
      "TD112_raw_512Hz\n",
      "Processing TD112_raw_512Hz\n",
      "td\n",
      "TD104_raw_512Hz\n",
      "Processing TD104_raw_512Hz\n",
      "td\n",
      "TD105_raw_512Hz\n",
      "Processing TD105_raw_512Hz\n",
      "td\n",
      "TD114_raw_512Hz\n",
      "Processing TD114_raw_512Hz\n",
      "td\n",
      "A109_raw_512Hz\n",
      "Processing A109_raw_512Hz\n",
      "asd\n",
      "A113_raw_512Hz\n",
      "Processing A113_raw_512Hz\n",
      "asd\n",
      "A103_raw_512Hz\n",
      "Processing A103_raw_512Hz\n",
      "asd\n",
      "A101_raw_512Hz\n",
      "Processing A101_raw_512Hz\n",
      "asd\n",
      "A112_raw_512Hz\n",
      "Processing A112_raw_512Hz\n",
      "asd\n",
      "A111_raw_512Hz\n",
      "Processing A111_raw_512Hz\n",
      "asd\n",
      "A104_raw_512Hz\n",
      "Processing A104_raw_512Hz\n",
      "asd\n",
      "A108_raw_512Hz\n",
      "Processing A108_raw_512Hz\n",
      "asd\n",
      "A114_raw_512Hz\n",
      "Processing A114_raw_512Hz\n",
      "asd\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "mne.set_log_level('CRITICAL')\n",
    "\n",
    "#import torch\n",
    "import os\n",
    "from pathlib import Path \n",
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing import annotate_muscle_zscore\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.time_frequency import tfr_morlet\n",
    "import math\n",
    "from mne.preprocessing import (create_eog_epochs, create_ecg_epochs,\n",
    "                               corrmap)\n",
    "#matplotlib.use('Qt5Agg')\n",
    "#mne.set_log_level('warning')\n",
    "print(\"eeg\")\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "raw_eeg_path = data_path / \"raw_eeg\"\n",
    "\n",
    "label_ids = {\n",
    "    \"asd\": 1,\n",
    "    \"td\": 2\n",
    "}\n",
    "\n",
    "study_epochs = {\n",
    "    'td': [],\n",
    "    'asd': []\n",
    "}\n",
    "\n",
    "# Assumes file is formatted as {ID}_{type}_{XXXHz}.{extension}. Example TD100_raw_512Hz.asc\n",
    "def csvToRaw(file, fMax=40):\n",
    "    print(f\"Processing {file.stem}\")\n",
    "    data = pd.read_csv(file, sep='\\t')\n",
    "\n",
    "    try:\n",
    "        data =  data.drop(['VEOG - LkE', 'HEOG - LkE', 'Unnamed: 34'], axis=1)\n",
    "    except:\n",
    "        print(\"No EOG Channels found\")\n",
    "    # Get Channels\n",
    "    channels = list(data.columns)\n",
    "\n",
    "    # Format Channel names\n",
    "    f = lambda str: str.split(\"-\")[0].replace(\" \", \"\")\n",
    "    channels = [f(x) for x in channels]\n",
    "    channel_count = len(channels)\n",
    "\n",
    "    # Load Data\n",
    "    data = data.transpose()\n",
    "    ch_types = np.full((channel_count), \"eeg\")\n",
    "    sfreq = int(file.stem.split(\"_\")[2].replace(\"Hz\", \"\"))\n",
    "    info = mne.create_info(ch_names = channels, sfreq = sfreq, ch_types=ch_types)\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "\n",
    "    # Format data date for annotations later\n",
    "    raw.set_meas_date(0)\n",
    "    raw.set_montage(\"standard_1020\")\n",
    "\n",
    "    # Convert from uV to V for MNE\n",
    "    raw.apply_function(lambda x: x * 1e-6)\n",
    "\n",
    "    # Mark bad data\n",
    "    # Addressing this later now\n",
    "    markMuscleArtifacts(raw, 2)\n",
    "\n",
    "    filtered = raw.copy().filter(l_freq=1.0, h_freq=fMax)\n",
    "\n",
    "    return raw, filtered\n",
    "\n",
    "# Find bad spans of data using mne.preprocessing.annotate_muscle_zscore\n",
    "def markMuscleArtifacts(raw, threshold, plot=False):\n",
    "    #print(\"markMuscleArtifacts\")\n",
    "    threshold_muscle = threshold  # z-score\n",
    "    annot_muscle, scores_muscle = annotate_muscle_zscore(\n",
    "    raw, ch_type=\"eeg\", threshold=threshold_muscle, min_length_good=0.2,\n",
    "    filter_freq=[0, 60])\n",
    "    raw.set_annotations(annot_muscle)\n",
    "\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        start = 512 * 10\n",
    "        end = 512 * 20\n",
    "        ax.plot(raw.times[:end], scores_muscle[:end])\n",
    "        ax.axhline(y=threshold_muscle, color='r')\n",
    "        ax.set(xlabel='time, (s)', ylabel='zscore', title='Muscle activity')\n",
    "        plt.show()\n",
    "\n",
    "def plot(raw, start=0, duration=10.0):\n",
    "    raw.plot(show_scrollbars=False, show_scalebars=False, duration=10.0, start=20.0)\n",
    "\n",
    "# Create epoch data, get ICs, and add to study_epochs object\n",
    "def addEpochs(data, raw, start, file_length_seconds, label, file=\"\",epochDuration=1):\n",
    "    stop = start + epochDuration\n",
    "    events = mne.make_fixed_length_events(data,  label_ids[label], start=start, stop=file_length_seconds, duration=epochDuration)\n",
    "    epochs = mne.Epochs(data, events, tmin=0, tmax=epochDuration, event_id={label: label_ids[label]}, baseline=(0, 0), preload=True)\n",
    "    #epochs.plot(title=\"before\")\n",
    "    dropBadEpochs(epochs)\n",
    "   \n",
    "    # Run ICA\n",
    "    ica = runICA(epochs)\n",
    "    eog_epochs = create_eog_epochs(raw, \"Fp1\")\n",
    "    eog_inds, eog_scores = ica.find_bads_eog(eog_epochs, \"Fp2\",  threshold=1.25)\n",
    "    ica.exclude = eog_inds\n",
    "    #print(eog_inds)\n",
    "\n",
    "    # Get Clean epochs\n",
    "    cleaned_epochs = ica.apply(epochs.copy())\n",
    "    #fig = cleaned_epochs.compute_psd().plot()\n",
    "    #fig.suptitle(file, fontsize=16)\n",
    "\n",
    "    #cleaned_epochs.plot(title=\"after\")\n",
    "    study_epochs[label].append(cleaned_epochs)\n",
    "    # update with cleaned epochs\n",
    "    return cleaned_epochs\n",
    "\n",
    "# Reject epochs based on maximum acceptable peak-to-peak amplitude \n",
    "# https://mne.tools/stable/auto_tutorials/preprocessing/20_rejecting_bad_data.html#sphx-glr-auto-tutorials-preprocessing-20-rejecting-bad-data-py\n",
    "def dropBadEpochs(epochs, plotLog=False):\n",
    "    reject_criteria = dict(eeg=150e-6) # 150 µV\n",
    "    flat_criteria = dict(eeg=1e-6) # 1 µV\n",
    "    epochs.drop_bad(reject=reject_criteria, flat=flat_criteria)\n",
    "    if plotLog: epochs.plot_drop_log()\n",
    "\n",
    "# Get ICs \n",
    "def runICA(epochs):\n",
    "    #print(\"Running ICA\")\n",
    "    n_components = 0.99  # Should normally be higher, like 0.999!!\n",
    "    method = 'picard'\n",
    "    # Picard method requires python 3.7\n",
    "    #method = 'fastica'\n",
    "    fit_params = dict(fastica_it=5)\n",
    "    random_state = 42\n",
    "\n",
    "    ica = mne.preprocessing.ICA(n_components=n_components,\n",
    "        method=method,\n",
    "        fit_params=fit_params,\n",
    "        random_state=random_state)\n",
    "\n",
    "    ica.fit(epochs)\n",
    "    return ica\n",
    " \n",
    "# Process raw file. \n",
    "def process(file, epoch_len_seconds):\n",
    "    raw, filtered = csvToRaw(file)\n",
    "    #plot(raw)\n",
    "    #plot(filtered)\n",
    "    #fig = filtered.complotRawpute_psd().plot()\n",
    "    file_length = math.floor(len(filtered.times) / float(filtered.info['sfreq']))\n",
    "    #print(f\"{file_length}s file length\")\n",
    "    label = file.parent.stem\n",
    "    print(label)\n",
    "    epochs = addEpochs(filtered, raw, epoch_len_seconds, file_length, label, file) \n",
    "    np_all_epochs = epochs.get_data()\n",
    "    #print(np_all_epochs.shape)\n",
    "\n",
    "    #return filtered, epochs\n",
    "    \n",
    "    \n",
    "def main():\n",
    "    dir = \"train\"\n",
    "    data_path_list = list(raw_eeg_path.glob(f\"{dir}/*/*.asc\"))\n",
    "    epoch_len_seconds = 1.0\n",
    "\n",
    "    \n",
    "    for file in data_path_list:\n",
    "        print(file.stem)\n",
    "        process(file, epoch_len_seconds)\n",
    "\n",
    "    asd_concat_epochs = mne.concatenate_epochs(study_epochs['asd'])\n",
    "    td_concat_epochs = mne.concatenate_epochs(study_epochs['td'])\n",
    "    asd_concat_epochs.save(Path('out_data/2023') / f'asd_concat_cleaned_1_40hz_epo.fif', overwrite=True)\n",
    "    td_concat_epochs.save(Path('out_data/2023') / f'td_concat_cleaned_1_40hz_epo.fif', overwrite=True)\n",
    "    train_all_epochs = mne.concatenate_epochs([asd_concat_epochs, td_concat_epochs])\n",
    "    train_all_epochs.equalize_event_counts(train_all_epochs.event_id)\n",
    "    train_all_epochs.save(Path('out_data/2023') / f'all_epo_asd_td.fif')\n",
    "    #print(study_epochs)\n",
    "    #process(data_path_list[0])\n",
    "    \n",
    "    #print(data_path_list)\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interpretable-cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
